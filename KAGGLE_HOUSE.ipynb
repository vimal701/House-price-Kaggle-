{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\HOUSE PRICING\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "for i in range(0,80):\n",
    "    if train_data.iloc[:,i].isnull().sum().any():\n",
    "        a.append(train_data.columns[i])\n",
    "        b.append(train_data.iloc[:,i].isnull().sum())\n",
    "        c.append(train_data.iloc[:,i].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df=pd.DataFrame(a,columns=['columns'])\n",
    "null_df['values']=pd.DataFrame(b)\n",
    "null_df['data_types']=pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train=train_data.drop(['Alley','Fence','MiscFeature','PoolQC'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train['MasVnrArea']=new_train['MasVnrArea'].fillna(new_train['MasVnrArea'].mean())\n",
    "new_train['GarageYrBlt']=new_train['GarageYrBlt'].fillna(new_train['GarageYrBlt'].mean())\n",
    "new_train['LotFrontage']=new_train['LotFrontage'].fillna(new_train['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,77):\n",
    "    if (new_train.iloc[:,i].dtypes)=='object':\n",
    "        new_train.iloc[:,i]=new_train.iloc[:,i].fillna(new_train.iloc[:,i].mode()[0])   \n",
    "      #  print(new_train.columns[i])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train['SaleCondition']=pd.get_dummies(new_train['SaleCondition'])\n",
    "new_train['SaleType']=pd.get_dummies(new_train['SaleType'])\n",
    "new_train['PavedDrive']=pd.get_dummies(new_train['PavedDrive'])\n",
    "new_train['GarageCond']=pd.get_dummies(new_train['GarageCond'])\n",
    "new_train['GarageQual']=pd.get_dummies(new_train['GarageQual'])\n",
    "new_train['GarageFinish']=pd.get_dummies(new_train['GarageFinish'])\n",
    "new_train['GarageType']=pd.get_dummies(new_train['GarageType'])\n",
    "new_train['FireplaceQu']=pd.get_dummies(new_train['FireplaceQu'])\n",
    "new_train['Functional']=pd.get_dummies(new_train['Functional'])\n",
    "new_train['KitchenQual']=pd.get_dummies(new_train['KitchenQual'])\n",
    "new_train['Electrical']=pd.get_dummies(new_train['Electrical'])\n",
    "new_train['CentralAir']=pd.get_dummies(new_train['CentralAir'])\n",
    "new_train['HeatingQC']=pd.get_dummies(new_train['HeatingQC'])\n",
    "new_train['Heating']=pd.get_dummies(new_train['Heating'])\n",
    "new_train['BsmtFinType2']=pd.get_dummies(new_train['BsmtFinType2'])\n",
    "new_train['BsmtFinType1']=pd.get_dummies(new_train['BsmtFinType1'])\n",
    "new_train['BsmtExposure']=pd.get_dummies(new_train['BsmtExposure'])\n",
    "new_train['BsmtCond']=pd.get_dummies(new_train['BsmtCond'])\n",
    "new_train['BsmtQual']=pd.get_dummies(new_train['BsmtQual'])\n",
    "new_train['Foundation']=pd.get_dummies(new_train['Foundation'])\n",
    "new_train['ExterCond']=pd.get_dummies(new_train['ExterCond'])\n",
    "new_train['ExterQual']=pd.get_dummies(new_train['ExterQual'])\n",
    "new_train['MasVnrType']=pd.get_dummies(new_train['MasVnrType'])\n",
    "new_train['Exterior2nd']=pd.get_dummies(new_train['Exterior2nd'])\n",
    "new_train['Exterior1st']=pd.get_dummies(new_train['Exterior1st'])\n",
    "new_train['RoofMatl']=pd.get_dummies(new_train['RoofMatl'])\n",
    "new_train['RoofStyle']=pd.get_dummies(new_train['RoofStyle'])\n",
    "new_train['HouseStyle']=pd.get_dummies(new_train['HouseStyle'])\n",
    "new_train['BldgType']=pd.get_dummies(new_train['BldgType'])\n",
    "new_train['Condition2']=pd.get_dummies(new_train['Condition2'])\n",
    "new_train['Condition1']=pd.get_dummies(new_train['Condition1'])\n",
    "new_train['Neighborhood']=pd.get_dummies(new_train['Neighborhood'])\n",
    "new_train['LandSlope']=pd.get_dummies(new_train['LandSlope'])\n",
    "new_train['LotConfig']=pd.get_dummies(new_train['LotConfig'])\n",
    "new_train['Utilities']=pd.get_dummies(new_train['Utilities'])\n",
    "new_train['LandContour']=pd.get_dummies(new_train['LandContour'])\n",
    "new_train['LotShape']=pd.get_dummies(new_train['LotShape'])\n",
    "new_train['Street']=pd.get_dummies(new_train['Street'])\n",
    "new_train['MSZoning']=pd.get_dummies(new_train['MSZoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in=new_train.iloc[:,0:76]\n",
    "train_out=new_train.iloc[:,76]\n",
    "train_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 76)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data=pd.read_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\HOUSE PRICING\\test_1.csv')\n",
    "del testing_data['Unnamed: 0']\n",
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#training,testing= train_test_split(train_in,test_size=0.2,random_state=0)\n",
    "#training_op,testing_op= train_test_split(train_out,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "#lg=LinearRegression()\n",
    "#lg.fit(train_in,train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred=lg.predict(testing_data)\n",
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Dense(units=50, kernel_initializer='he_uniform', activation='relu',input_dim=76))\n",
    "classifier.add(Dense(units=25, kernel_initializer='he_uniform', activation='relu'))\n",
    "classifier.add(Dense(units=50, kernel_initializer='he_uniform', activation='relu'))\n",
    "classifier.add(Dense(units=1, kernel_initializer='he_uniform'))\n",
    "classifier.compile(optimizer='Adamax',loss=root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 782 samples, validate on 386 samples\n",
      "Epoch 1/500\n",
      "782/782 [==============================] - 0s 553us/step - loss: 34961.8726 - val_loss: 31520.5837\n",
      "Epoch 2/500\n",
      "782/782 [==============================] - 0s 627us/step - loss: 35180.1639 - val_loss: 31761.0267\n",
      "Epoch 3/500\n",
      "782/782 [==============================] - 1s 735us/step - loss: 35540.0661 - val_loss: 32785.6716\n",
      "Epoch 4/500\n",
      "782/782 [==============================] - 1s 675us/step - loss: 34855.1342 - val_loss: 31340.0913\n",
      "Epoch 5/500\n",
      "782/782 [==============================] - 0s 558us/step - loss: 35459.2545 - val_loss: 32777.5766\n",
      "Epoch 6/500\n",
      "782/782 [==============================] - 0s 579us/step - loss: 35547.1449 - val_loss: 31420.1075\n",
      "Epoch 7/500\n",
      "782/782 [==============================] - 0s 635us/step - loss: 34989.2554 - val_loss: 31201.7453\n",
      "Epoch 8/500\n",
      "782/782 [==============================] - 0s 587us/step - loss: 35387.1618 - val_loss: 31150.7262\n",
      "Epoch 9/500\n",
      "782/782 [==============================] - 1s 666us/step - loss: 34765.5433 - val_loss: 32004.0148\n",
      "Epoch 10/500\n",
      "782/782 [==============================] - 0s 539us/step - loss: 34995.4429 - val_loss: 31169.7743\n",
      "Epoch 11/500\n",
      "782/782 [==============================] - 0s 560us/step - loss: 34829.0144 - val_loss: 31079.0065\n",
      "Epoch 12/500\n",
      "782/782 [==============================] - 1s 664us/step - loss: 35176.4828 - val_loss: 31276.7579\n",
      "Epoch 13/500\n",
      "782/782 [==============================] - 0s 621us/step - loss: 34946.7169 - val_loss: 33540.1911\n",
      "Epoch 14/500\n",
      "782/782 [==============================] - 0s 633us/step - loss: 35554.9302 - val_loss: 31348.4750\n",
      "Epoch 15/500\n",
      "782/782 [==============================] - 0s 618us/step - loss: 35069.2445 - val_loss: 31133.2723\n",
      "Epoch 16/500\n",
      "782/782 [==============================] - 0s 540us/step - loss: 35032.4829 - val_loss: 30984.4459\n",
      "Epoch 17/500\n",
      "782/782 [==============================] - 1s 682us/step - loss: 34890.3435 - val_loss: 31094.8901\n",
      "Epoch 18/500\n",
      "782/782 [==============================] - 0s 592us/step - loss: 35506.2954 - val_loss: 30784.0747\n",
      "Epoch 19/500\n",
      "782/782 [==============================] - 0s 631us/step - loss: 35044.6635 - val_loss: 32063.2119\n",
      "Epoch 20/500\n",
      "782/782 [==============================] - 0s 490us/step - loss: 34656.6724 - val_loss: 30737.2115\n",
      "Epoch 21/500\n",
      "782/782 [==============================] - 0s 615us/step - loss: 35590.1945 - val_loss: 30871.9147\n",
      "Epoch 22/500\n",
      "782/782 [==============================] - 1s 973us/step - loss: 34936.3259 - val_loss: 32421.8616\n",
      "Epoch 23/500\n",
      "782/782 [==============================] - 0s 603us/step - loss: 35778.4624 - val_loss: 30791.8631\n",
      "Epoch 24/500\n",
      "782/782 [==============================] - 1s 674us/step - loss: 35596.8800 - val_loss: 32420.2335\n",
      "Epoch 25/500\n",
      "782/782 [==============================] - 0s 531us/step - loss: 35394.0482 - val_loss: 30779.7009\n",
      "Epoch 26/500\n",
      "782/782 [==============================] - 0s 552us/step - loss: 35092.9102 - val_loss: 30915.9285\n",
      "Epoch 27/500\n",
      "782/782 [==============================] - 1s 759us/step - loss: 34669.1669 - val_loss: 31180.8449\n",
      "Epoch 28/500\n",
      "782/782 [==============================] - 0s 484us/step - loss: 35670.5398 - val_loss: 31300.4687\n",
      "Epoch 29/500\n",
      "782/782 [==============================] - 1s 648us/step - loss: 34420.5425 - val_loss: 31298.1277\n",
      "Epoch 30/500\n",
      "782/782 [==============================] - 0s 621us/step - loss: 34697.3288 - val_loss: 31294.2768\n",
      "Epoch 31/500\n",
      "782/782 [==============================] - 0s 491us/step - loss: 34809.4791 - val_loss: 31145.3420\n",
      "Epoch 32/500\n",
      "782/782 [==============================] - 1s 711us/step - loss: 34062.2748 - val_loss: 31677.1619\n",
      "Epoch 33/500\n",
      "782/782 [==============================] - 0s 561us/step - loss: 35115.7742 - val_loss: 33845.0116\n",
      "Epoch 34/500\n",
      "782/782 [==============================] - 1s 786us/step - loss: 34705.1332 - val_loss: 33150.5137\n",
      "Epoch 35/500\n",
      "782/782 [==============================] - 0s 620us/step - loss: 35157.8716 - val_loss: 32122.8047\n",
      "Epoch 36/500\n",
      "782/782 [==============================] - 1s 647us/step - loss: 34740.4240 - val_loss: 31635.8836\n",
      "Epoch 37/500\n",
      "782/782 [==============================] - 1s 698us/step - loss: 34796.3665 - val_loss: 31136.2097\n",
      "Epoch 38/500\n",
      "782/782 [==============================] - 0s 518us/step - loss: 34847.2056 - val_loss: 30760.5435\n",
      "Epoch 39/500\n",
      "782/782 [==============================] - 1s 775us/step - loss: 35057.3384 - val_loss: 31147.9371\n",
      "Epoch 40/500\n",
      "782/782 [==============================] - 0s 551us/step - loss: 34759.8513 - val_loss: 31126.4659\n",
      "Epoch 41/500\n",
      "782/782 [==============================] - 0s 519us/step - loss: 35112.4433 - val_loss: 30437.1403\n",
      "Epoch 42/500\n",
      "782/782 [==============================] - 1s 756us/step - loss: 35141.9781 - val_loss: 32150.6748\n",
      "Epoch 43/500\n",
      "782/782 [==============================] - 0s 472us/step - loss: 34728.6324 - val_loss: 30781.3475\n",
      "Epoch 44/500\n",
      "782/782 [==============================] - 1s 769us/step - loss: 34925.3520 - val_loss: 30781.5964\n",
      "Epoch 45/500\n",
      "782/782 [==============================] - 0s 541us/step - loss: 34253.5359 - val_loss: 30420.8021\n",
      "Epoch 46/500\n",
      "782/782 [==============================] - 0s 521us/step - loss: 34793.9212 - val_loss: 31188.0410\n",
      "Epoch 47/500\n",
      "782/782 [==============================] - 1s 896us/step - loss: 34337.1291 - val_loss: 32653.7692\n",
      "Epoch 48/500\n",
      "782/782 [==============================] - 0s 512us/step - loss: 34751.4117 - val_loss: 30536.9792\n",
      "Epoch 49/500\n",
      "782/782 [==============================] - 1s 788us/step - loss: 34268.7917 - val_loss: 31729.4048\n",
      "Epoch 50/500\n",
      "782/782 [==============================] - 0s 503us/step - loss: 34761.9044 - val_loss: 30987.6165\n",
      "Epoch 51/500\n",
      "782/782 [==============================] - 0s 494us/step - loss: 34194.7062 - val_loss: 30396.6890\n",
      "Epoch 52/500\n",
      "782/782 [==============================] - 1s 863us/step - loss: 34453.3275 - val_loss: 31550.9140\n",
      "Epoch 53/500\n",
      "782/782 [==============================] - 0s 603us/step - loss: 34566.9561 - val_loss: 32024.7966\n",
      "Epoch 54/500\n",
      "782/782 [==============================] - 0s 541us/step - loss: 34260.5175 - val_loss: 30645.9638\n",
      "Epoch 55/500\n",
      "782/782 [==============================] - 1s 830us/step - loss: 34745.6378 - val_loss: 30883.8954\n",
      "Epoch 56/500\n",
      "782/782 [==============================] - ETA: 0s - loss: 35414.526 - 0s 567us/step - loss: 34772.1213 - val_loss: 30631.3272\n",
      "Epoch 57/500\n",
      "782/782 [==============================] - 1s 911us/step - loss: 34627.3553 - val_loss: 30879.0318\n",
      "Epoch 58/500\n",
      "782/782 [==============================] - 0s 600us/step - loss: 34352.8321 - val_loss: 30484.2809\n",
      "Epoch 59/500\n",
      "782/782 [==============================] - 0s 443us/step - loss: 34406.7454 - val_loss: 30253.6301\n",
      "Epoch 60/500\n",
      "782/782 [==============================] - 1s 865us/step - loss: 34539.5650 - val_loss: 31412.7314\n",
      "Epoch 61/500\n",
      "782/782 [==============================] - 0s 559us/step - loss: 34174.0008 - val_loss: 30598.9474\n",
      "Epoch 62/500\n",
      "782/782 [==============================] - 1s 892us/step - loss: 33818.1834 - val_loss: 30608.3539\n",
      "Epoch 63/500\n",
      "782/782 [==============================] - 0s 535us/step - loss: 34721.9504 - val_loss: 31995.6111\n",
      "Epoch 64/500\n",
      "782/782 [==============================] - 0s 551us/step - loss: 34561.6230 - val_loss: 30208.0076\n",
      "Epoch 65/500\n",
      "782/782 [==============================] - 1s 856us/step - loss: 34572.8740 - val_loss: 32378.6089\n",
      "Epoch 66/500\n",
      "782/782 [==============================] - 0s 606us/step - loss: 34819.5142 - val_loss: 30585.7587\n",
      "Epoch 67/500\n",
      "782/782 [==============================] - 1s 798us/step - loss: 35084.8160 - val_loss: 31406.6631\n",
      "Epoch 68/500\n",
      "782/782 [==============================] - 0s 563us/step - loss: 34513.9389 - val_loss: 30882.3690\n",
      "Epoch 69/500\n",
      "782/782 [==============================] - 1s 662us/step - loss: 34645.9367 - val_loss: 31276.7147\n",
      "Epoch 70/500\n",
      "782/782 [==============================] - 1s 832us/step - loss: 34569.3960 - val_loss: 30191.8762\n",
      "Epoch 71/500\n",
      "782/782 [==============================] - 0s 591us/step - loss: 34226.6861 - val_loss: 32151.4854\n",
      "Epoch 72/500\n",
      "782/782 [==============================] - 1s 828us/step - loss: 34951.5496 - val_loss: 33057.2055\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 465us/step - loss: 34805.6896 - val_loss: 30874.0504\n",
      "Epoch 74/500\n",
      "782/782 [==============================] - 0s 518us/step - loss: 34140.7262 - val_loss: 30896.5481\n",
      "Epoch 75/500\n",
      "782/782 [==============================] - 1s 746us/step - loss: 33930.3976 - val_loss: 30233.5929\n",
      "Epoch 76/500\n",
      "782/782 [==============================] - 0s 521us/step - loss: 34674.1011 - val_loss: 32692.0088\n",
      "Epoch 77/500\n",
      "782/782 [==============================] - 0s 544us/step - loss: 34450.4409 - val_loss: 31059.6034\n",
      "Epoch 78/500\n",
      "782/782 [==============================] - 0s 565us/step - loss: 33894.8442 - val_loss: 31148.9006\n",
      "Epoch 79/500\n",
      "782/782 [==============================] - 0s 521us/step - loss: 34533.0875 - val_loss: 30682.3255\n",
      "Epoch 80/500\n",
      "782/782 [==============================] - 1s 694us/step - loss: 34170.8537 - val_loss: 30296.4053\n",
      "Epoch 81/500\n",
      "782/782 [==============================] - 0s 554us/step - loss: 34796.6005 - val_loss: 32396.9312\n",
      "Epoch 82/500\n",
      "782/782 [==============================] - 0s 489us/step - loss: 34164.1168 - val_loss: 30657.1362\n",
      "Epoch 83/500\n",
      "782/782 [==============================] - 1s 670us/step - loss: 34242.7184 - val_loss: 31137.6304\n",
      "Epoch 84/500\n",
      "782/782 [==============================] - 0s 522us/step - loss: 34542.5871 - val_loss: 31837.6493\n",
      "Epoch 85/500\n",
      "782/782 [==============================] - 0s 475us/step - loss: 34727.9175 - val_loss: 30148.9495\n",
      "Epoch 86/500\n",
      "782/782 [==============================] - 1s 811us/step - loss: 33960.2242 - val_loss: 30765.9125\n",
      "Epoch 87/500\n",
      "782/782 [==============================] - 0s 473us/step - loss: 34544.8924 - val_loss: 30553.3644\n",
      "Epoch 88/500\n",
      "782/782 [==============================] - 0s 577us/step - loss: 34195.3189 - val_loss: 30274.4859\n",
      "Epoch 89/500\n",
      "782/782 [==============================] - 1s 770us/step - loss: 34069.2250 - val_loss: 30320.1410\n",
      "Epoch 90/500\n",
      "782/782 [==============================] - 0s 462us/step - loss: 33515.4777 - val_loss: 34044.2390\n",
      "Epoch 91/500\n",
      "782/782 [==============================] - 1s 804us/step - loss: 34246.8197 - val_loss: 30625.5559\n",
      "Epoch 92/500\n",
      "782/782 [==============================] - 0s 466us/step - loss: 33870.9029 - val_loss: 32051.1889\n",
      "Epoch 93/500\n",
      "782/782 [==============================] - 0s 570us/step - loss: 34254.7696 - val_loss: 30053.1099\n",
      "Epoch 94/500\n",
      "782/782 [==============================] - 1s 673us/step - loss: 34493.8011 - val_loss: 30776.0699\n",
      "Epoch 95/500\n",
      "782/782 [==============================] - 0s 513us/step - loss: 33617.9647 - val_loss: 32453.9405\n",
      "Epoch 96/500\n",
      "782/782 [==============================] - 0s 625us/step - loss: 34329.8059 - val_loss: 30441.1366\n",
      "Epoch 97/500\n",
      "782/782 [==============================] - 0s 567us/step - loss: 34327.6117 - val_loss: 30117.1084\n",
      "Epoch 98/500\n",
      "782/782 [==============================] - 0s 492us/step - loss: 34184.5467 - val_loss: 30828.7205\n",
      "Epoch 99/500\n",
      "782/782 [==============================] - 1s 669us/step - loss: 34231.4821 - val_loss: 30320.2469\n",
      "Epoch 100/500\n",
      "782/782 [==============================] - 0s 448us/step - loss: 33978.3326 - val_loss: 30297.9174\n",
      "Epoch 101/500\n",
      "782/782 [==============================] - 0s 578us/step - loss: 33977.4923 - val_loss: 30059.8956\n",
      "Epoch 102/500\n",
      "782/782 [==============================] - 0s 583us/step - loss: 33730.5945 - val_loss: 30448.1822\n",
      "Epoch 103/500\n",
      "782/782 [==============================] - 0s 459us/step - loss: 33700.1007 - val_loss: 31448.2179\n",
      "Epoch 104/500\n",
      "782/782 [==============================] - 0s 627us/step - loss: 34332.1423 - val_loss: 31619.1953\n",
      "Epoch 105/500\n",
      "782/782 [==============================] - 0s 597us/step - loss: 33872.8986 - val_loss: 31479.6963\n",
      "Epoch 106/500\n",
      "782/782 [==============================] - 0s 481us/step - loss: 33628.5673 - val_loss: 29805.1044\n",
      "Epoch 107/500\n",
      "782/782 [==============================] - 1s 731us/step - loss: 33262.6611 - val_loss: 31448.5113\n",
      "Epoch 108/500\n",
      "782/782 [==============================] - 0s 546us/step - loss: 33850.8487 - val_loss: 33247.5171\n",
      "Epoch 109/500\n",
      "782/782 [==============================] - 1s 648us/step - loss: 33644.8032 - val_loss: 31800.4956\n",
      "Epoch 110/500\n",
      "782/782 [==============================] - 0s 599us/step - loss: 33924.9075 - val_loss: 30154.4311\n",
      "Epoch 111/500\n",
      "782/782 [==============================] - 0s 463us/step - loss: 33916.5187 - val_loss: 29881.0485\n",
      "Epoch 112/500\n",
      "782/782 [==============================] - 1s 696us/step - loss: 34043.3775 - val_loss: 30226.8903\n",
      "Epoch 113/500\n",
      "782/782 [==============================] - 0s 470us/step - loss: 33761.6098 - val_loss: 30724.9634\n",
      "Epoch 114/500\n",
      "782/782 [==============================] - 0s 581us/step - loss: 33738.9703 - val_loss: 31201.3748\n",
      "Epoch 115/500\n",
      "782/782 [==============================] - 0s 638us/step - loss: 33835.1572 - val_loss: 29897.0346\n",
      "Epoch 116/500\n",
      "782/782 [==============================] - 0s 445us/step - loss: 33913.8676 - val_loss: 30776.2092\n",
      "Epoch 117/500\n",
      "782/782 [==============================] - 1s 751us/step - loss: 33752.4574 - val_loss: 29991.6044\n",
      "Epoch 118/500\n",
      "782/782 [==============================] - 0s 481us/step - loss: 33878.6992 - val_loss: 30410.4170\n",
      "Epoch 119/500\n",
      "782/782 [==============================] - 0s 493us/step - loss: 34307.6320 - val_loss: 30630.1524\n",
      "Epoch 120/500\n",
      "782/782 [==============================] - 1s 780us/step - loss: 33722.6974 - val_loss: 30114.4203\n",
      "Epoch 121/500\n",
      "782/782 [==============================] - 0s 471us/step - loss: 34029.8238 - val_loss: 30099.6299\n",
      "Epoch 122/500\n",
      "782/782 [==============================] - 1s 771us/step - loss: 33925.2980 - val_loss: 30116.3348\n",
      "Epoch 123/500\n",
      "782/782 [==============================] - 0s 556us/step - loss: 33503.3805 - val_loss: 29934.3452\n",
      "Epoch 124/500\n",
      "782/782 [==============================] - 0s 462us/step - loss: 33424.2123 - val_loss: 29532.2968\n",
      "Epoch 125/500\n",
      "782/782 [==============================] - 1s 737us/step - loss: 33325.7490 - val_loss: 30529.2822\n",
      "Epoch 126/500\n",
      "782/782 [==============================] - 0s 471us/step - loss: 33626.9731 - val_loss: 30692.0579\n",
      "Epoch 127/500\n",
      "782/782 [==============================] - 0s 465us/step - loss: 33313.8677 - val_loss: 30716.0667\n",
      "Epoch 128/500\n",
      "782/782 [==============================] - 1s 792us/step - loss: 33943.8932 - val_loss: 30158.1346\n",
      "Epoch 129/500\n",
      "782/782 [==============================] - 0s 445us/step - loss: 33507.2749 - val_loss: 30084.2373\n",
      "Epoch 130/500\n",
      "782/782 [==============================] - 0s 566us/step - loss: 33690.3812 - val_loss: 30222.2184\n",
      "Epoch 131/500\n",
      "782/782 [==============================] - 1s 703us/step - loss: 33550.9811 - val_loss: 29899.1191\n",
      "Epoch 132/500\n",
      "782/782 [==============================] - 0s 483us/step - loss: 33734.9319 - val_loss: 29983.0632\n",
      "Epoch 133/500\n",
      "782/782 [==============================] - 0s 487us/step - loss: 33080.6700 - val_loss: 30129.2617\n",
      "Epoch 134/500\n",
      "782/782 [==============================] - 1s 685us/step - loss: 33258.2946 - val_loss: 33810.8040\n",
      "Epoch 135/500\n",
      "782/782 [==============================] - 0s 525us/step - loss: 33865.7737 - val_loss: 29837.8536\n",
      "Epoch 136/500\n",
      "782/782 [==============================] - 0s 616us/step - loss: 33019.9317 - val_loss: 29912.4792\n",
      "Epoch 137/500\n",
      "782/782 [==============================] - 0s 529us/step - loss: 33190.1611 - val_loss: 29549.7238\n",
      "Epoch 138/500\n",
      "782/782 [==============================] - 0s 502us/step - loss: 34075.3815 - val_loss: 29809.9954\n",
      "Epoch 139/500\n",
      "782/782 [==============================] - 1s 699us/step - loss: 33423.3728 - val_loss: 29851.3160\n",
      "Epoch 140/500\n",
      "782/782 [==============================] - 0s 479us/step - loss: 33560.7186 - val_loss: 30078.2091\n",
      "Epoch 141/500\n",
      "782/782 [==============================] - 0s 590us/step - loss: 33440.9266 - val_loss: 30139.8584\n",
      "Epoch 142/500\n",
      "782/782 [==============================] - 0s 589us/step - loss: 33542.1528 - val_loss: 29270.3909\n",
      "Epoch 143/500\n",
      "782/782 [==============================] - 0s 534us/step - loss: 32979.6697 - val_loss: 29922.9737\n",
      "Epoch 144/500\n",
      "782/782 [==============================] - 0s 591us/step - loss: 33709.9260 - val_loss: 30273.9675\n",
      "Epoch 145/500\n",
      "782/782 [==============================] - 0s 540us/step - loss: 33552.3622 - val_loss: 29647.9318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/500\n",
      "782/782 [==============================] - 0s 519us/step - loss: 33899.6164 - val_loss: 29136.6539\n",
      "Epoch 147/500\n",
      "782/782 [==============================] - 1s 739us/step - loss: 33406.0962 - val_loss: 29795.1854\n",
      "Epoch 148/500\n",
      "782/782 [==============================] - 0s 516us/step - loss: 33216.7998 - val_loss: 29709.7009\n",
      "Epoch 149/500\n",
      "782/782 [==============================] - 1s 644us/step - loss: 33308.1886 - val_loss: 30349.8872\n",
      "Epoch 150/500\n",
      "782/782 [==============================] - 0s 620us/step - loss: 32840.0195 - val_loss: 29459.0434\n",
      "Epoch 151/500\n",
      "782/782 [==============================] - 0s 570us/step - loss: 33552.6218 - val_loss: 30628.0152\n",
      "Epoch 152/500\n",
      "782/782 [==============================] - 1s 729us/step - loss: 33011.7338 - val_loss: 29861.0146\n",
      "Epoch 153/500\n",
      "782/782 [==============================] - 0s 512us/step - loss: 33237.8055 - val_loss: 29892.8217\n",
      "Epoch 154/500\n",
      "782/782 [==============================] - 0s 600us/step - loss: 32592.6637 - val_loss: 30536.7818\n",
      "Epoch 155/500\n",
      "782/782 [==============================] - 1s 646us/step - loss: 32641.4598 - val_loss: 29726.9999\n",
      "Epoch 156/500\n",
      "782/782 [==============================] - 0s 519us/step - loss: 33283.8108 - val_loss: 30358.3060\n",
      "Epoch 157/500\n",
      "782/782 [==============================] - 0s 568us/step - loss: 33166.8374 - val_loss: 30034.0260\n",
      "Epoch 158/500\n",
      "782/782 [==============================] - 0s 582us/step - loss: 32549.7394 - val_loss: 30742.6547\n",
      "Epoch 159/500\n",
      "782/782 [==============================] - 0s 576us/step - loss: 33615.7277 - val_loss: 30150.7153\n",
      "Epoch 160/500\n",
      "782/782 [==============================] - 0s 587us/step - loss: 32824.1196 - val_loss: 30773.3164\n",
      "Epoch 161/500\n",
      "782/782 [==============================] - 0s 570us/step - loss: 33049.0491 - val_loss: 31031.9999\n",
      "Epoch 162/500\n",
      "782/782 [==============================] - 0s 584us/step - loss: 33013.2450 - val_loss: 30005.9884\n",
      "Epoch 163/500\n",
      "782/782 [==============================] - 1s 670us/step - loss: 32405.7929 - val_loss: 29516.2208\n",
      "Epoch 164/500\n",
      "782/782 [==============================] - 0s 534us/step - loss: 33014.9790 - val_loss: 29598.3536\n",
      "Epoch 165/500\n",
      "782/782 [==============================] - 0s 546us/step - loss: 33122.3727 - val_loss: 29630.2487\n",
      "Epoch 166/500\n",
      "782/782 [==============================] - 0s 559us/step - loss: 31827.2304 - val_loss: 30661.5985\n",
      "Epoch 167/500\n",
      "782/782 [==============================] - 0s 536us/step - loss: 32697.5499 - val_loss: 29830.3510\n",
      "Epoch 168/500\n",
      "782/782 [==============================] - 0s 573us/step - loss: 32718.4633 - val_loss: 29903.8747\n",
      "Epoch 169/500\n",
      "782/782 [==============================] - 0s 556us/step - loss: 32730.1090 - val_loss: 29968.4923\n",
      "Epoch 170/500\n",
      "782/782 [==============================] - 0s 546us/step - loss: 32667.6198 - val_loss: 30552.7721\n",
      "Epoch 171/500\n",
      "782/782 [==============================] - 0s 599us/step - loss: 32997.6597 - val_loss: 30074.4543\n",
      "Epoch 172/500\n",
      "782/782 [==============================] - 0s 580us/step - loss: 33598.2915 - val_loss: 30109.1230\n",
      "Epoch 173/500\n",
      "782/782 [==============================] - 0s 498us/step - loss: 32421.3767 - val_loss: 30406.8584\n",
      "Epoch 174/500\n",
      "782/782 [==============================] - 1s 643us/step - loss: 32318.7211 - val_loss: 29562.3776\n",
      "Epoch 175/500\n",
      "782/782 [==============================] - 0s 516us/step - loss: 32889.2986 - val_loss: 29604.2708\n",
      "Epoch 176/500\n",
      "782/782 [==============================] - 0s 636us/step - loss: 32744.7056 - val_loss: 29572.2618\n",
      "Epoch 177/500\n",
      "782/782 [==============================] - 0s 539us/step - loss: 32505.4006 - val_loss: 29568.5842\n",
      "Epoch 178/500\n",
      "782/782 [==============================] - 0s 589us/step - loss: 33006.9348 - val_loss: 29308.0361\n",
      "Epoch 179/500\n",
      "782/782 [==============================] - 1s 654us/step - loss: 32215.7312 - val_loss: 30314.1805\n",
      "Epoch 180/500\n",
      "782/782 [==============================] - ETA: 0s - loss: 32598.589 - 0s 555us/step - loss: 32560.9164 - val_loss: 30689.8945\n",
      "Epoch 181/500\n",
      "782/782 [==============================] - 0s 588us/step - loss: 33328.0357 - val_loss: 29519.1933\n",
      "Epoch 182/500\n",
      "782/782 [==============================] - 0s 577us/step - loss: 32497.6400 - val_loss: 29916.5787\n",
      "Epoch 183/500\n",
      "782/782 [==============================] - 0s 510us/step - loss: 32494.1171 - val_loss: 30184.2795\n",
      "Epoch 184/500\n",
      "782/782 [==============================] - 0s 628us/step - loss: 32802.2707 - val_loss: 29393.1873\n",
      "Epoch 185/500\n",
      "782/782 [==============================] - 0s 599us/step - loss: 32444.2903 - val_loss: 29137.5378\n",
      "Epoch 186/500\n",
      "782/782 [==============================] - 0s 514us/step - loss: 32463.1132 - val_loss: 29448.3080\n",
      "Epoch 187/500\n",
      "782/782 [==============================] - 1s 748us/step - loss: 32528.9886 - val_loss: 29037.7216\n",
      "Epoch 188/500\n",
      "782/782 [==============================] - 0s 536us/step - loss: 32783.7291 - val_loss: 29961.3096\n",
      "Epoch 189/500\n",
      "782/782 [==============================] - 0s 625us/step - loss: 32687.1016 - val_loss: 29276.0307\n",
      "Epoch 190/500\n",
      "782/782 [==============================] - 0s 522us/step - loss: 32191.0397 - val_loss: 31273.5649\n",
      "Epoch 191/500\n",
      "782/782 [==============================] - 0s 533us/step - loss: 32890.2549 - val_loss: 29651.3438\n",
      "Epoch 192/500\n",
      "782/782 [==============================] - 1s 651us/step - loss: 32717.9706 - val_loss: 30744.1451\n",
      "Epoch 193/500\n",
      "782/782 [==============================] - 0s 566us/step - loss: 33729.9982 - val_loss: 29490.5509\n",
      "Epoch 194/500\n",
      "782/782 [==============================] - 0s 540us/step - loss: 32803.8978 - val_loss: 29479.9496\n",
      "Epoch 195/500\n",
      "782/782 [==============================] - 1s 666us/step - loss: 32282.5502 - val_loss: 29480.4137\n",
      "Epoch 196/500\n",
      "782/782 [==============================] - 0s 538us/step - loss: 32247.9567 - val_loss: 29200.6592\n",
      "Epoch 197/500\n",
      "782/782 [==============================] - 0s 629us/step - loss: 32083.0616 - val_loss: 30946.7860\n",
      "Epoch 198/500\n",
      "782/782 [==============================] - 0s 568us/step - loss: 32745.8520 - val_loss: 33396.5292\n",
      "Epoch 199/500\n",
      "782/782 [==============================] - 0s 492us/step - loss: 33177.1931 - val_loss: 29461.8781\n",
      "Epoch 200/500\n",
      "782/782 [==============================] - 1s 704us/step - loss: 32481.8179 - val_loss: 30214.7130\n",
      "Epoch 201/500\n",
      "782/782 [==============================] - 0s 499us/step - loss: 31733.1467 - val_loss: 29207.8681\n",
      "Epoch 202/500\n",
      "782/782 [==============================] - 0s 569us/step - loss: 32914.2292 - val_loss: 29410.2772\n",
      "Epoch 203/500\n",
      "782/782 [==============================] - 0s 624us/step - loss: 32329.5055 - val_loss: 29254.2312\n",
      "Epoch 204/500\n",
      "782/782 [==============================] - 0s 499us/step - loss: 32360.6407 - val_loss: 29359.8705\n",
      "Epoch 205/500\n",
      "782/782 [==============================] - 1s 675us/step - loss: 33213.6365 - val_loss: 29350.8044\n",
      "Epoch 206/500\n",
      "782/782 [==============================] - 0s 488us/step - loss: 31858.6994 - val_loss: 30043.8308\n",
      "Epoch 207/500\n",
      "782/782 [==============================] - 0s 575us/step - loss: 32000.7118 - val_loss: 30461.5571\n",
      "Epoch 208/500\n",
      "782/782 [==============================] - 1s 654us/step - loss: 32226.4073 - val_loss: 30280.5229\n",
      "Epoch 209/500\n",
      "782/782 [==============================] - 0s 452us/step - loss: 31946.0999 - val_loss: 31554.2408\n",
      "Epoch 210/500\n",
      "782/782 [==============================] - 0s 550us/step - loss: 31958.6762 - val_loss: 29099.1098\n",
      "Epoch 211/500\n",
      "782/782 [==============================] - 1s 645us/step - loss: 32221.1808 - val_loss: 29207.9288\n",
      "Epoch 212/500\n",
      "782/782 [==============================] - 0s 549us/step - loss: 32721.2175 - val_loss: 29082.4440\n",
      "Epoch 213/500\n",
      "782/782 [==============================] - 0s 637us/step - loss: 32224.6226 - val_loss: 29971.8151\n",
      "Epoch 214/500\n",
      "782/782 [==============================] - 0s 504us/step - loss: 31895.2153 - val_loss: 29081.0005\n",
      "Epoch 215/500\n",
      "782/782 [==============================] - 0s 534us/step - loss: 31877.7308 - val_loss: 29049.2105\n",
      "Epoch 216/500\n",
      "782/782 [==============================] - 1s 689us/step - loss: 32076.8001 - val_loss: 32008.0266\n",
      "Epoch 217/500\n",
      "782/782 [==============================] - 0s 456us/step - loss: 33757.5763 - val_loss: 29690.3387\n",
      "Epoch 218/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 645us/step - loss: 32469.3400 - val_loss: 30115.5560\n",
      "Epoch 219/500\n",
      "782/782 [==============================] - 0s 603us/step - loss: 32435.5818 - val_loss: 28855.3752\n",
      "Epoch 220/500\n",
      "782/782 [==============================] - 0s 506us/step - loss: 32431.3984 - val_loss: 29085.8356\n",
      "Epoch 221/500\n",
      "782/782 [==============================] - 0s 614us/step - loss: 31789.9669 - val_loss: 30050.2788\n",
      "Epoch 222/500\n",
      "782/782 [==============================] - 0s 549us/step - loss: 32354.5560 - val_loss: 30634.2639\n",
      "Epoch 223/500\n",
      "782/782 [==============================] - 0s 560us/step - loss: 32243.9268 - val_loss: 29419.5177\n",
      "Epoch 224/500\n",
      "782/782 [==============================] - 0s 607us/step - loss: 31575.1888 - val_loss: 29399.9888\n",
      "Epoch 225/500\n",
      "782/782 [==============================] - 0s 495us/step - loss: 32250.1859 - val_loss: 29382.9582\n",
      "Epoch 226/500\n",
      "782/782 [==============================] - 0s 553us/step - loss: 31663.3431 - val_loss: 30732.3841\n",
      "Epoch 227/500\n",
      "782/782 [==============================] - 1s 645us/step - loss: 32277.2371 - val_loss: 29736.4196\n",
      "Epoch 228/500\n",
      "782/782 [==============================] - 0s 569us/step - loss: 31955.6555 - val_loss: 29714.1476\n",
      "Epoch 229/500\n",
      "782/782 [==============================] - 1s 702us/step - loss: 32323.5737 - val_loss: 31299.4103\n",
      "Epoch 230/500\n",
      "782/782 [==============================] - 0s 525us/step - loss: 32128.2899 - val_loss: 30282.0743\n",
      "Epoch 231/500\n",
      "782/782 [==============================] - 0s 577us/step - loss: 31706.3968 - val_loss: 30585.8836\n",
      "Epoch 232/500\n",
      "782/782 [==============================] - 0s 584us/step - loss: 31676.3955 - val_loss: 29422.7527\n",
      "Epoch 233/500\n",
      "782/782 [==============================] - 0s 562us/step - loss: 31772.8314 - val_loss: 29757.5609\n",
      "Epoch 234/500\n",
      "782/782 [==============================] - 0s 550us/step - loss: 32357.0085 - val_loss: 30100.6010\n",
      "Epoch 235/500\n",
      "782/782 [==============================] - 0s 628us/step - loss: 31980.3630 - val_loss: 28804.5203\n",
      "Epoch 236/500\n",
      "782/782 [==============================] - 0s 563us/step - loss: 31282.1881 - val_loss: 28924.3754\n",
      "Epoch 237/500\n",
      "782/782 [==============================] - 0s 616us/step - loss: 31957.3056 - val_loss: 31479.4774\n",
      "Epoch 238/500\n",
      "782/782 [==============================] - 0s 564us/step - loss: 32436.9716 - val_loss: 31482.5209\n",
      "Epoch 239/500\n",
      "782/782 [==============================] - 0s 555us/step - loss: 32265.8413 - val_loss: 29386.4435\n",
      "Epoch 240/500\n",
      "782/782 [==============================] - 1s 687us/step - loss: 31719.8895 - val_loss: 30106.9715\n",
      "Epoch 241/500\n",
      "782/782 [==============================] - 0s 562us/step - loss: 31564.7632 - val_loss: 29573.5917\n",
      "Epoch 242/500\n",
      "782/782 [==============================] - 0s 582us/step - loss: 31331.1557 - val_loss: 28945.7197\n",
      "Epoch 243/500\n",
      "782/782 [==============================] - 0s 614us/step - loss: 31728.4350 - val_loss: 29454.9925\n",
      "Epoch 244/500\n",
      "782/782 [==============================] - 0s 521us/step - loss: 31665.8221 - val_loss: 29810.3763\n",
      "Epoch 245/500\n",
      "782/782 [==============================] - 1s 664us/step - loss: 32117.3952 - val_loss: 31285.7137\n",
      "Epoch 246/500\n",
      "782/782 [==============================] - 0s 563us/step - loss: 31434.4081 - val_loss: 29148.4352\n",
      "Epoch 247/500\n",
      "782/782 [==============================] - 0s 533us/step - loss: 31581.8592 - val_loss: 29378.8531\n",
      "Epoch 248/500\n",
      "782/782 [==============================] - 0s 621us/step - loss: 31367.9221 - val_loss: 29382.5784\n",
      "Epoch 249/500\n",
      "782/782 [==============================] - 1s 647us/step - loss: 31847.6888 - val_loss: 29262.4453\n",
      "Epoch 250/500\n",
      "782/782 [==============================] - 1s 696us/step - loss: 31533.5813 - val_loss: 28838.3158\n",
      "Epoch 251/500\n",
      "782/782 [==============================] - 0s 549us/step - loss: 31889.4353 - val_loss: 28836.2741\n",
      "Epoch 252/500\n",
      "782/782 [==============================] - 0s 554us/step - loss: 31140.9349 - val_loss: 28974.4196\n",
      "Epoch 253/500\n",
      "782/782 [==============================] - 1s 768us/step - loss: 32330.3965 - val_loss: 29015.1830\n",
      "Epoch 254/500\n",
      "782/782 [==============================] - 0s 525us/step - loss: 31309.5311 - val_loss: 29099.3751\n",
      "Epoch 255/500\n",
      "782/782 [==============================] - 0s 595us/step - loss: 31861.8629 - val_loss: 30096.6390\n",
      "Epoch 256/500\n",
      "782/782 [==============================] - 1s 713us/step - loss: 31509.0528 - val_loss: 30573.5434\n",
      "Epoch 257/500\n",
      "782/782 [==============================] - 0s 597us/step - loss: 31577.1332 - val_loss: 29078.1002\n",
      "Epoch 258/500\n",
      "782/782 [==============================] - 1s 708us/step - loss: 31126.3177 - val_loss: 29431.9217\n",
      "Epoch 259/500\n",
      "782/782 [==============================] - 0s 510us/step - loss: 31008.8309 - val_loss: 30580.6385\n",
      "Epoch 260/500\n",
      "782/782 [==============================] - 0s 600us/step - loss: 31672.8538 - val_loss: 30049.3050\n",
      "Epoch 261/500\n",
      "782/782 [==============================] - 1s 682us/step - loss: 31476.3489 - val_loss: 29356.0877\n",
      "Epoch 262/500\n",
      "782/782 [==============================] - 0s 509us/step - loss: 31255.3611 - val_loss: 30033.3979\n",
      "Epoch 263/500\n",
      "782/782 [==============================] - 1s 642us/step - loss: 31106.6021 - val_loss: 29025.2813\n",
      "Epoch 264/500\n",
      "782/782 [==============================] - 0s 519us/step - loss: 31393.5715 - val_loss: 28650.0922\n",
      "Epoch 265/500\n",
      "782/782 [==============================] - 0s 578us/step - loss: 31547.3108 - val_loss: 29940.6330\n",
      "Epoch 266/500\n",
      "782/782 [==============================] - 0s 591us/step - loss: 30724.5076 - val_loss: 29628.1729\n",
      "Epoch 267/500\n",
      "782/782 [==============================] - 0s 528us/step - loss: 31230.8505 - val_loss: 29610.3679\n",
      "Epoch 268/500\n",
      "782/782 [==============================] - 0s 618us/step - loss: 31300.1746 - val_loss: 29895.8407\n",
      "Epoch 269/500\n",
      "782/782 [==============================] - 0s 549us/step - loss: 30764.4777 - val_loss: 29191.0307\n",
      "Epoch 270/500\n",
      "782/782 [==============================] - 0s 573us/step - loss: 30444.7791 - val_loss: 32236.4245\n",
      "Epoch 271/500\n",
      "782/782 [==============================] - 1s 661us/step - loss: 31368.0664 - val_loss: 29938.6584\n",
      "Epoch 272/500\n",
      "782/782 [==============================] - 0s 529us/step - loss: 31106.6761 - val_loss: 29910.4887\n",
      "Epoch 273/500\n",
      "782/782 [==============================] - 0s 615us/step - loss: 31008.7797 - val_loss: 29996.4371\n",
      "Epoch 274/500\n",
      "782/782 [==============================] - 0s 586us/step - loss: 30638.1349 - val_loss: 29783.4911\n",
      "Epoch 275/500\n",
      "782/782 [==============================] - 0s 535us/step - loss: 30747.4035 - val_loss: 31374.8337\n",
      "Epoch 276/500\n",
      "782/782 [==============================] - 1s 847us/step - loss: 30959.2136 - val_loss: 28561.9383\n",
      "Epoch 277/500\n",
      "782/782 [==============================] - 0s 526us/step - loss: 30962.8716 - val_loss: 29010.3389\n",
      "Epoch 278/500\n",
      "782/782 [==============================] - 0s 611us/step - loss: 31326.7032 - val_loss: 29537.6873\n",
      "Epoch 279/500\n",
      "782/782 [==============================] - 0s 591us/step - loss: 30660.4106 - val_loss: 29221.3306\n",
      "Epoch 280/500\n",
      "782/782 [==============================] - 0s 519us/step - loss: 30898.6089 - val_loss: 28742.5342\n",
      "Epoch 281/500\n",
      "782/782 [==============================] - 1s 643us/step - loss: 30790.4357 - val_loss: 28797.4620\n",
      "Epoch 282/500\n",
      "782/782 [==============================] - 0s 582us/step - loss: 30706.3856 - val_loss: 29875.7550\n",
      "Epoch 283/500\n",
      "782/782 [==============================] - 0s 478us/step - loss: 30646.0372 - val_loss: 28978.9104\n",
      "Epoch 284/500\n",
      "782/782 [==============================] - 1s 745us/step - loss: 30918.2690 - val_loss: 28856.9487\n",
      "Epoch 285/500\n",
      "782/782 [==============================] - 0s 506us/step - loss: 31220.9499 - val_loss: 28928.9233\n",
      "Epoch 286/500\n",
      "782/782 [==============================] - 0s 497us/step - loss: 31237.3670 - val_loss: 28506.0810\n",
      "Epoch 287/500\n",
      "782/782 [==============================] - 1s 721us/step - loss: 30508.2054 - val_loss: 29573.8214\n",
      "Epoch 288/500\n",
      "782/782 [==============================] - 0s 493us/step - loss: 30861.3487 - val_loss: 30463.2269\n",
      "Epoch 289/500\n",
      "782/782 [==============================] - 0s 617us/step - loss: 31183.7893 - val_loss: 28686.8248\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 566us/step - loss: 31170.2496 - val_loss: 29238.6413\n",
      "Epoch 291/500\n",
      "782/782 [==============================] - 0s 465us/step - loss: 30662.9213 - val_loss: 28853.0541\n",
      "Epoch 292/500\n",
      "782/782 [==============================] - 1s 729us/step - loss: 30504.3945 - val_loss: 30747.9208\n",
      "Epoch 293/500\n",
      "782/782 [==============================] - 0s 493us/step - loss: 30365.6145 - val_loss: 29211.7250\n",
      "Epoch 294/500\n",
      "782/782 [==============================] - 0s 451us/step - loss: 30583.8630 - val_loss: 28634.2081\n",
      "Epoch 295/500\n",
      "782/782 [==============================] - 1s 782us/step - loss: 30825.3053 - val_loss: 28623.6392\n",
      "Epoch 296/500\n",
      "782/782 [==============================] - 0s 474us/step - loss: 30467.7003 - val_loss: 29035.1516\n",
      "Epoch 297/500\n",
      "782/782 [==============================] - 0s 477us/step - loss: 30602.0991 - val_loss: 28884.7570\n",
      "Epoch 298/500\n",
      "782/782 [==============================] - 1s 760us/step - loss: 30605.0002 - val_loss: 28754.2523\n",
      "Epoch 299/500\n",
      "782/782 [==============================] - 0s 479us/step - loss: 30934.3538 - val_loss: 28709.0520\n",
      "Epoch 300/500\n",
      "782/782 [==============================] - 0s 518us/step - loss: 30747.3605 - val_loss: 30150.4218\n",
      "Epoch 301/500\n",
      "782/782 [==============================] - 1s 693us/step - loss: 31558.5180 - val_loss: 29185.0283\n",
      "Epoch 302/500\n",
      "782/782 [==============================] - 0s 454us/step - loss: 30419.6502 - val_loss: 29369.1481\n",
      "Epoch 303/500\n",
      "782/782 [==============================] - 0s 506us/step - loss: 30931.8663 - val_loss: 28422.2357\n",
      "Epoch 304/500\n",
      "782/782 [==============================] - 0s 605us/step - loss: 30246.6044 - val_loss: 28359.7249\n",
      "Epoch 305/500\n",
      "782/782 [==============================] - 0s 458us/step - loss: 29917.7228 - val_loss: 29046.7056\n",
      "Epoch 306/500\n",
      "782/782 [==============================] - 0s 538us/step - loss: 30524.3236 - val_loss: 28902.7258\n",
      "Epoch 307/500\n",
      "782/782 [==============================] - 1s 677us/step - loss: 30681.0980 - val_loss: 29094.2142\n",
      "Epoch 308/500\n",
      "782/782 [==============================] - 0s 449us/step - loss: 30500.4764 - val_loss: 29160.5748\n",
      "Epoch 309/500\n",
      "782/782 [==============================] - 1s 733us/step - loss: 30619.0913 - val_loss: 29488.9093\n",
      "Epoch 310/500\n",
      "782/782 [==============================] - 0s 501us/step - loss: 30479.7327 - val_loss: 28653.6419\n",
      "Epoch 311/500\n",
      "782/782 [==============================] - 0s 455us/step - loss: 30301.8036 - val_loss: 28590.7664\n",
      "Epoch 312/500\n",
      "782/782 [==============================] - 1s 816us/step - loss: 30359.2844 - val_loss: 29498.8366\n",
      "Epoch 313/500\n",
      "782/782 [==============================] - 0s 467us/step - loss: 30440.5539 - val_loss: 28467.9910\n",
      "Epoch 314/500\n",
      "782/782 [==============================] - 0s 462us/step - loss: 31052.8518 - val_loss: 30536.2227\n",
      "Epoch 315/500\n",
      "782/782 [==============================] - 1s 815us/step - loss: 30313.8508 - val_loss: 29612.6131\n",
      "Epoch 316/500\n",
      "782/782 [==============================] - 0s 456us/step - loss: 30192.2191 - val_loss: 28703.0087\n",
      "Epoch 317/500\n",
      "782/782 [==============================] - ETA: 0s - loss: 31227.084 - 0s 573us/step - loss: 30809.1256 - val_loss: 28324.6198\n",
      "Epoch 318/500\n",
      "782/782 [==============================] - 0s 623us/step - loss: 30167.3690 - val_loss: 28989.2815\n",
      "Epoch 319/500\n",
      "782/782 [==============================] - 0s 476us/step - loss: 29889.9503 - val_loss: 28859.7346\n",
      "Epoch 320/500\n",
      "782/782 [==============================] - 1s 709us/step - loss: 30224.0752 - val_loss: 28371.3517\n",
      "Epoch 321/500\n",
      "782/782 [==============================] - 0s 483us/step - loss: 30346.0356 - val_loss: 28875.1895\n",
      "Epoch 322/500\n",
      "782/782 [==============================] - 0s 459us/step - loss: 29837.9577 - val_loss: 29174.2469\n",
      "Epoch 323/500\n",
      "782/782 [==============================] - 1s 805us/step - loss: 30007.1277 - val_loss: 28266.1477\n",
      "Epoch 324/500\n",
      "782/782 [==============================] - 0s 435us/step - loss: 30424.4387 - val_loss: 30946.7570\n",
      "Epoch 325/500\n",
      "782/782 [==============================] - 0s 461us/step - loss: 29647.2865 - val_loss: 28381.9781\n",
      "Epoch 326/500\n",
      "782/782 [==============================] - 1s 801us/step - loss: 30780.6073 - val_loss: 29698.9413\n",
      "Epoch 327/500\n",
      "782/782 [==============================] - 0s 464us/step - loss: 30093.1120 - val_loss: 28859.7560\n",
      "Epoch 328/500\n",
      "782/782 [==============================] - 0s 465us/step - loss: 29879.4671 - val_loss: 29229.4805\n",
      "Epoch 329/500\n",
      "782/782 [==============================] - 1s 777us/step - loss: 29831.4902 - val_loss: 29724.0802\n",
      "Epoch 330/500\n",
      "782/782 [==============================] - 0s 468us/step - loss: 30717.8364 - val_loss: 30359.1369\n",
      "Epoch 331/500\n",
      "782/782 [==============================] - 0s 461us/step - loss: 30904.8085 - val_loss: 29135.5569\n",
      "Epoch 332/500\n",
      "782/782 [==============================] - 1s 805us/step - loss: 30306.6372 - val_loss: 28954.6631\n",
      "Epoch 333/500\n",
      "782/782 [==============================] - 0s 458us/step - loss: 29857.0116 - val_loss: 28505.3961\n",
      "Epoch 334/500\n",
      "782/782 [==============================] - 0s 470us/step - loss: 29626.7674 - val_loss: 29526.2131\n",
      "Epoch 335/500\n",
      "782/782 [==============================] - 1s 790us/step - loss: 29546.7841 - val_loss: 28390.6154\n",
      "Epoch 336/500\n",
      "782/782 [==============================] - 0s 458us/step - loss: 29723.6047 - val_loss: 28938.5602\n",
      "Epoch 337/500\n",
      "782/782 [==============================] - 0s 415us/step - loss: 29925.8177 - val_loss: 28584.0965\n",
      "Epoch 338/500\n",
      "782/782 [==============================] - 1s 971us/step - loss: 29450.2295 - val_loss: 28653.9024\n",
      "Epoch 339/500\n",
      "782/782 [==============================] - 0s 512us/step - loss: 29741.2275 - val_loss: 29350.6063\n",
      "Epoch 340/500\n",
      "782/782 [==============================] - 1s 806us/step - loss: 29775.3044 - val_loss: 28413.4604\n",
      "Epoch 341/500\n",
      "782/782 [==============================] - ETA: 0s - loss: 30492.920 - 0s 441us/step - loss: 30311.1930 - val_loss: 28618.8862\n",
      "Epoch 342/500\n",
      "782/782 [==============================] - 0s 469us/step - loss: 29962.5282 - val_loss: 29364.8290\n",
      "Epoch 343/500\n",
      "782/782 [==============================] - 1s 828us/step - loss: 29738.8510 - val_loss: 29267.7529\n",
      "Epoch 344/500\n",
      "782/782 [==============================] - 0s 458us/step - loss: 29498.8334 - val_loss: 28638.0018\n",
      "Epoch 345/500\n",
      "782/782 [==============================] - 0s 474us/step - loss: 29889.4793 - val_loss: 28582.2828\n",
      "Epoch 346/500\n",
      "782/782 [==============================] - 1s 782us/step - loss: 29870.4337 - val_loss: 28733.1061\n",
      "Epoch 347/500\n",
      "782/782 [==============================] - 0s 483us/step - loss: 30161.9361 - val_loss: 28346.1548\n",
      "Epoch 348/500\n",
      "782/782 [==============================] - 0s 444us/step - loss: 29263.3975 - val_loss: 28819.9650\n",
      "Epoch 349/500\n",
      "782/782 [==============================] - 1s 887us/step - loss: 29172.0467 - val_loss: 29201.7758\n",
      "Epoch 350/500\n",
      "782/782 [==============================] - 0s 464us/step - loss: 29810.6625 - val_loss: 28344.6333\n",
      "Epoch 351/500\n",
      "782/782 [==============================] - 0s 484us/step - loss: 29384.0400 - val_loss: 29125.9452\n",
      "Epoch 352/500\n",
      "782/782 [==============================] - 1s 732us/step - loss: 29816.5426 - val_loss: 28920.5839\n",
      "Epoch 353/500\n",
      "782/782 [==============================] - 0s 448us/step - loss: 29454.9786 - val_loss: 30060.5856\n",
      "Epoch 354/500\n",
      "782/782 [==============================] - 0s 489us/step - loss: 29443.6923 - val_loss: 28424.2875\n",
      "Epoch 355/500\n",
      "782/782 [==============================] - 1s 701us/step - loss: 29793.2661 - val_loss: 30121.4432\n",
      "Epoch 356/500\n",
      "782/782 [==============================] - 0s 480us/step - loss: 29022.9097 - val_loss: 29199.6667\n",
      "Epoch 357/500\n",
      "782/782 [==============================] - 0s 490us/step - loss: 29508.5803 - val_loss: 29639.2976\n",
      "Epoch 358/500\n",
      "782/782 [==============================] - 1s 739us/step - loss: 29298.1834 - val_loss: 29234.9685\n",
      "Epoch 359/500\n",
      "782/782 [==============================] - 0s 455us/step - loss: 29384.8469 - val_loss: 30701.1009\n",
      "Epoch 360/500\n",
      "782/782 [==============================] - 1s 735us/step - loss: 29433.5109 - val_loss: 28321.2009\n",
      "Epoch 361/500\n",
      "782/782 [==============================] - 0s 476us/step - loss: 29013.5190 - val_loss: 28753.1284\n",
      "Epoch 362/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 472us/step - loss: 29610.1582 - val_loss: 28426.7498\n",
      "Epoch 363/500\n",
      "782/782 [==============================] - 0s 592us/step - loss: 29324.7462 - val_loss: 29695.4938\n",
      "Epoch 364/500\n",
      "782/782 [==============================] - 0s 524us/step - loss: 29191.3862 - val_loss: 35557.7853\n",
      "Epoch 365/500\n",
      "782/782 [==============================] - 0s 431us/step - loss: 29301.6189 - val_loss: 29257.8445\n",
      "Epoch 366/500\n",
      "782/782 [==============================] - 1s 775us/step - loss: 28755.3605 - val_loss: 30139.4655\n",
      "Epoch 367/500\n",
      "782/782 [==============================] - 0s 475us/step - loss: 29645.7464 - val_loss: 28582.2293\n",
      "Epoch 368/500\n",
      "782/782 [==============================] - 0s 475us/step - loss: 29126.3112 - val_loss: 28343.7427\n",
      "Epoch 369/500\n",
      "782/782 [==============================] - 1s 730us/step - loss: 30006.3316 - val_loss: 31065.4560\n",
      "Epoch 370/500\n",
      "782/782 [==============================] - 0s 485us/step - loss: 30192.5633 - val_loss: 28536.5105\n",
      "Epoch 371/500\n",
      "782/782 [==============================] - 0s 491us/step - loss: 29232.4127 - val_loss: 28747.7129\n",
      "Epoch 372/500\n",
      "782/782 [==============================] - 1s 780us/step - loss: 29675.2867 - val_loss: 28535.6633\n",
      "Epoch 373/500\n",
      "782/782 [==============================] - 0s 504us/step - loss: 28464.5423 - val_loss: 28367.3623\n",
      "Epoch 374/500\n",
      "782/782 [==============================] - 1s 703us/step - loss: 29613.5727 - val_loss: 28593.4647\n",
      "Epoch 375/500\n",
      "782/782 [==============================] - 0s 551us/step - loss: 28835.1932 - val_loss: 28062.0049\n",
      "Epoch 376/500\n",
      "782/782 [==============================] - 0s 514us/step - loss: 29078.7875 - val_loss: 28528.6615\n",
      "Epoch 377/500\n",
      "782/782 [==============================] - 1s 731us/step - loss: 29072.6860 - val_loss: 32643.9097\n",
      "Epoch 378/500\n",
      "782/782 [==============================] - 0s 459us/step - loss: 29216.5176 - val_loss: 29927.3000\n",
      "Epoch 379/500\n",
      "782/782 [==============================] - 0s 512us/step - loss: 29059.7265 - val_loss: 32592.1717\n",
      "Epoch 380/500\n",
      "782/782 [==============================] - 1s 760us/step - loss: 28937.8182 - val_loss: 28332.6144\n",
      "Epoch 381/500\n",
      "782/782 [==============================] - 0s 520us/step - loss: 27792.3660 - val_loss: 28618.8518\n",
      "Epoch 382/500\n",
      "782/782 [==============================] - 1s 645us/step - loss: 28306.7443 - val_loss: 28524.2697\n",
      "Epoch 383/500\n",
      "782/782 [==============================] - 1s 691us/step - loss: 28730.3528 - val_loss: 28373.5118\n",
      "Epoch 384/500\n",
      "782/782 [==============================] - 0s 485us/step - loss: 28317.6037 - val_loss: 28503.5200\n",
      "Epoch 385/500\n",
      "782/782 [==============================] - 1s 643us/step - loss: 28844.6602 - val_loss: 28280.2739\n",
      "Epoch 386/500\n",
      "782/782 [==============================] - 0s 543us/step - loss: 29107.2409 - val_loss: 28549.6862\n",
      "Epoch 387/500\n",
      "782/782 [==============================] - 0s 449us/step - loss: 28290.9391 - val_loss: 28312.0847\n",
      "Epoch 388/500\n",
      "782/782 [==============================] - 1s 721us/step - loss: 27962.2789 - val_loss: 28924.3117\n",
      "Epoch 389/500\n",
      "782/782 [==============================] - 0s 477us/step - loss: 29066.0495 - val_loss: 28634.0619\n",
      "Epoch 390/500\n",
      "782/782 [==============================] - 0s 486us/step - loss: 28985.0174 - val_loss: 28119.2367\n",
      "Epoch 391/500\n",
      "782/782 [==============================] - 1s 779us/step - loss: 28046.7743 - val_loss: 28273.5028\n",
      "Epoch 392/500\n",
      "782/782 [==============================] - 0s 460us/step - loss: 28630.2024 - val_loss: 27884.9353\n",
      "Epoch 393/500\n",
      "782/782 [==============================] - 0s 534us/step - loss: 28175.4210 - val_loss: 30011.5229\n",
      "Epoch 394/500\n",
      "782/782 [==============================] - 1s 688us/step - loss: 28140.0721 - val_loss: 27811.7982\n",
      "Epoch 395/500\n",
      "782/782 [==============================] - 0s 520us/step - loss: 28223.5576 - val_loss: 31290.0490\n",
      "Epoch 396/500\n",
      "782/782 [==============================] - 0s 511us/step - loss: 28605.9125 - val_loss: 27912.0543\n",
      "Epoch 397/500\n",
      "782/782 [==============================] - 1s 664us/step - loss: 28230.5494 - val_loss: 28135.8281\n",
      "Epoch 398/500\n",
      "782/782 [==============================] - 0s 518us/step - loss: 28546.3761 - val_loss: 28120.7869\n",
      "Epoch 399/500\n",
      "782/782 [==============================] - 1s 668us/step - loss: 28538.0022 - val_loss: 30427.6643\n",
      "Epoch 400/500\n",
      "782/782 [==============================] - 0s 462us/step - loss: 28595.1326 - val_loss: 28502.9355\n",
      "Epoch 401/500\n",
      "782/782 [==============================] - 0s 514us/step - loss: 28208.7772 - val_loss: 28653.7007\n",
      "Epoch 402/500\n",
      "782/782 [==============================] - 1s 747us/step - loss: 28030.1390 - val_loss: 28848.5114\n",
      "Epoch 403/500\n",
      "782/782 [==============================] - 0s 524us/step - loss: 28391.0828 - val_loss: 28758.9706\n",
      "Epoch 404/500\n",
      "782/782 [==============================] - 0s 535us/step - loss: 28121.2774 - val_loss: 29880.5475\n",
      "Epoch 405/500\n",
      "782/782 [==============================] - 1s 705us/step - loss: 27935.5563 - val_loss: 28743.8090\n",
      "Epoch 406/500\n",
      "782/782 [==============================] - 0s 528us/step - loss: 27930.7769 - val_loss: 28336.4373\n",
      "Epoch 407/500\n",
      "782/782 [==============================] - 0s 459us/step - loss: 27711.6644 - val_loss: 28240.7867\n",
      "Epoch 408/500\n",
      "782/782 [==============================] - 1s 821us/step - loss: 28009.7085 - val_loss: 31006.7766\n",
      "Epoch 409/500\n",
      "782/782 [==============================] - 0s 459us/step - loss: 28227.4946 - val_loss: 28677.8951\n",
      "Epoch 410/500\n",
      "782/782 [==============================] - 1s 677us/step - loss: 27660.1624 - val_loss: 28293.3391\n",
      "Epoch 411/500\n",
      "782/782 [==============================] - 0s 519us/step - loss: 28160.0094 - val_loss: 28467.4708\n",
      "Epoch 412/500\n",
      "782/782 [==============================] - 0s 462us/step - loss: 27288.4235 - val_loss: 28781.1659\n",
      "Epoch 413/500\n",
      "782/782 [==============================] - 1s 812us/step - loss: 28258.9541 - val_loss: 28437.0100\n",
      "Epoch 414/500\n",
      "782/782 [==============================] - 0s 439us/step - loss: 27537.2899 - val_loss: 28893.9471\n",
      "Epoch 415/500\n",
      "782/782 [==============================] - 0s 517us/step - loss: 27894.7170 - val_loss: 28065.8287\n",
      "Epoch 416/500\n",
      "782/782 [==============================] - 1s 813us/step - loss: 27695.6183 - val_loss: 28638.3034\n",
      "Epoch 417/500\n",
      "782/782 [==============================] - 0s 476us/step - loss: 27339.6600 - val_loss: 28260.8732\n",
      "Epoch 418/500\n",
      "782/782 [==============================] - 0s 474us/step - loss: 28109.1397 - val_loss: 27750.6027\n",
      "Epoch 419/500\n",
      "782/782 [==============================] - 1s 769us/step - loss: 28083.5671 - val_loss: 28418.6025\n",
      "Epoch 420/500\n",
      "782/782 [==============================] - 0s 447us/step - loss: 27198.8516 - val_loss: 28142.7572\n",
      "Epoch 421/500\n",
      "782/782 [==============================] - 0s 469us/step - loss: 27739.0349 - val_loss: 28188.8024\n",
      "Epoch 422/500\n",
      "782/782 [==============================] - 1s 783us/step - loss: 27463.6669 - val_loss: 29576.4289\n",
      "Epoch 423/500\n",
      "782/782 [==============================] - 0s 462us/step - loss: 27918.3786 - val_loss: 28419.9236\n",
      "Epoch 424/500\n",
      "782/782 [==============================] - 0s 468us/step - loss: 27910.7276 - val_loss: 29075.1323\n",
      "Epoch 425/500\n",
      "782/782 [==============================] - 1s 756us/step - loss: 27337.7495 - val_loss: 29750.9941\n",
      "Epoch 426/500\n",
      "782/782 [==============================] - 0s 514us/step - loss: 27701.2127 - val_loss: 29172.4063\n",
      "Epoch 427/500\n",
      "782/782 [==============================] - 1s 715us/step - loss: 27666.7874 - val_loss: 28329.2615\n",
      "Epoch 428/500\n",
      "782/782 [==============================] - 0s 509us/step - loss: 27641.1226 - val_loss: 28201.0885\n",
      "Epoch 429/500\n",
      "782/782 [==============================] - 0s 435us/step - loss: 27557.7534 - val_loss: 27711.3735\n",
      "Epoch 430/500\n",
      "782/782 [==============================] - 1s 774us/step - loss: 27873.2448 - val_loss: 28501.4214\n",
      "Epoch 431/500\n",
      "782/782 [==============================] - 0s 449us/step - loss: 27449.1953 - val_loss: 28499.5589\n",
      "Epoch 432/500\n",
      "782/782 [==============================] - 0s 455us/step - loss: 27829.8637 - val_loss: 28301.2791\n",
      "Epoch 433/500\n",
      "782/782 [==============================] - 1s 793us/step - loss: 27354.1568 - val_loss: 28289.2174\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 484us/step - loss: 28229.2210 - val_loss: 27637.6593\n",
      "Epoch 435/500\n",
      "782/782 [==============================] - 0s 426us/step - loss: 27335.1546 - val_loss: 29370.0039\n",
      "Epoch 436/500\n",
      "782/782 [==============================] - 1s 825us/step - loss: 27401.1039 - val_loss: 28897.2926\n",
      "Epoch 437/500\n",
      "782/782 [==============================] - 0s 503us/step - loss: 27567.9158 - val_loss: 29710.3298\n",
      "Epoch 438/500\n",
      "782/782 [==============================] - 0s 460us/step - loss: 27184.4082 - val_loss: 28158.3964\n",
      "Epoch 439/500\n",
      "782/782 [==============================] - 1s 821us/step - loss: 27555.2609 - val_loss: 29172.1487\n",
      "Epoch 440/500\n",
      "782/782 [==============================] - 0s 472us/step - loss: 27603.8063 - val_loss: 28449.3575\n",
      "Epoch 441/500\n",
      "782/782 [==============================] - 0s 476us/step - loss: 28079.2933 - val_loss: 28127.7305\n",
      "Epoch 442/500\n",
      "782/782 [==============================] - 1s 833us/step - loss: 27208.0649 - val_loss: 28658.7862\n",
      "Epoch 443/500\n",
      "782/782 [==============================] - 0s 461us/step - loss: 27612.1589 - val_loss: 29330.9445\n",
      "Epoch 444/500\n",
      "782/782 [==============================] - 0s 517us/step - loss: 28340.2597 - val_loss: 27528.7813\n",
      "Epoch 445/500\n",
      "782/782 [==============================] - 1s 757us/step - loss: 27266.7164 - val_loss: 27605.3728\n",
      "Epoch 446/500\n",
      "782/782 [==============================] - 0s 456us/step - loss: 27629.3211 - val_loss: 28977.7626\n",
      "Epoch 447/500\n",
      "782/782 [==============================] - 1s 757us/step - loss: 27680.1190 - val_loss: 27358.9139\n",
      "Epoch 448/500\n",
      "782/782 [==============================] - 0s 521us/step - loss: 27666.8026 - val_loss: 28098.2999\n",
      "Epoch 449/500\n",
      "782/782 [==============================] - 0s 521us/step - loss: 27704.5399 - val_loss: 29194.1492\n",
      "Epoch 450/500\n",
      "782/782 [==============================] - 1s 723us/step - loss: 27665.4405 - val_loss: 27576.2390\n",
      "Epoch 451/500\n",
      "782/782 [==============================] - 0s 461us/step - loss: 26720.1476 - val_loss: 27148.3991\n",
      "Epoch 452/500\n",
      "782/782 [==============================] - 0s 553us/step - loss: 27488.9023 - val_loss: 27374.4862\n",
      "Epoch 453/500\n",
      "782/782 [==============================] - 1s 726us/step - loss: 26964.9147 - val_loss: 27565.6400\n",
      "Epoch 454/500\n",
      "782/782 [==============================] - 0s 526us/step - loss: 27147.8673 - val_loss: 27518.6314\n",
      "Epoch 455/500\n",
      "782/782 [==============================] - 0s 603us/step - loss: 26253.9337 - val_loss: 27787.9149\n",
      "Epoch 456/500\n",
      "782/782 [==============================] - 0s 536us/step - loss: 26947.6165 - val_loss: 28476.6232\n",
      "Epoch 457/500\n",
      "782/782 [==============================] - 0s 530us/step - loss: 26511.9958 - val_loss: 27378.6044\n",
      "Epoch 458/500\n",
      "782/782 [==============================] - 1s 764us/step - loss: 27558.6484 - val_loss: 27989.3560\n",
      "Epoch 459/500\n",
      "782/782 [==============================] - 0s 524us/step - loss: 27154.5859 - val_loss: 28206.2835\n",
      "Epoch 460/500\n",
      "782/782 [==============================] - 0s 459us/step - loss: 27230.0915 - val_loss: 27513.0067\n",
      "Epoch 461/500\n",
      "782/782 [==============================] - 1s 767us/step - loss: 26850.8579 - val_loss: 27352.9546\n",
      "Epoch 462/500\n",
      "782/782 [==============================] - 0s 528us/step - loss: 26316.7333 - val_loss: 28610.1849\n",
      "Epoch 463/500\n",
      "782/782 [==============================] - 0s 448us/step - loss: 26901.1238 - val_loss: 27776.5569\n",
      "Epoch 464/500\n",
      "782/782 [==============================] - 1s 675us/step - loss: 26135.8573 - val_loss: 27489.9233\n",
      "Epoch 465/500\n",
      "782/782 [==============================] - 0s 420us/step - loss: 25738.2344 - val_loss: 27697.9259\n",
      "Epoch 466/500\n",
      "782/782 [==============================] - 1s 683us/step - loss: 26262.1564 - val_loss: 27220.1827\n",
      "Epoch 467/500\n",
      "782/782 [==============================] - 0s 543us/step - loss: 27235.8638 - val_loss: 27452.5537\n",
      "Epoch 468/500\n",
      "782/782 [==============================] - 0s 455us/step - loss: 26730.0139 - val_loss: 27717.0840\n",
      "Epoch 469/500\n",
      "782/782 [==============================] - 1s 694us/step - loss: 26979.0649 - val_loss: 28665.9818\n",
      "Epoch 470/500\n",
      "782/782 [==============================] - 0s 480us/step - loss: 26903.3624 - val_loss: 27478.5508\n",
      "Epoch 471/500\n",
      "782/782 [==============================] - 0s 451us/step - loss: 26669.1413 - val_loss: 27054.4919\n",
      "Epoch 472/500\n",
      "782/782 [==============================] - 1s 844us/step - loss: 26886.7641 - val_loss: 32572.0709\n",
      "Epoch 473/500\n",
      "782/782 [==============================] - 0s 439us/step - loss: 27039.2204 - val_loss: 28176.7360\n",
      "Epoch 474/500\n",
      "782/782 [==============================] - 0s 553us/step - loss: 26763.3948 - val_loss: 27554.8242\n",
      "Epoch 475/500\n",
      "782/782 [==============================] - 1s 705us/step - loss: 27448.7008 - val_loss: 27215.1360\n",
      "Epoch 476/500\n",
      "782/782 [==============================] - 0s 476us/step - loss: 26266.0505 - val_loss: 27902.0363\n",
      "Epoch 477/500\n",
      "782/782 [==============================] - 0s 532us/step - loss: 26371.5484 - val_loss: 27478.8699\n",
      "Epoch 478/500\n",
      "782/782 [==============================] - 0s 638us/step - loss: 26023.0690 - val_loss: 27058.9209\n",
      "Epoch 479/500\n",
      "782/782 [==============================] - 0s 472us/step - loss: 26219.9125 - val_loss: 27524.2838\n",
      "Epoch 480/500\n",
      "782/782 [==============================] - 1s 776us/step - loss: 25954.1784 - val_loss: 27920.8765\n",
      "Epoch 481/500\n",
      "782/782 [==============================] - 0s 525us/step - loss: 26497.2812 - val_loss: 26998.1879\n",
      "Epoch 482/500\n",
      "782/782 [==============================] - 0s 496us/step - loss: 25416.9853 - val_loss: 27040.4482\n",
      "Epoch 483/500\n",
      "782/782 [==============================] - 1s 791us/step - loss: 26339.7542 - val_loss: 27500.5007\n",
      "Epoch 484/500\n",
      "782/782 [==============================] - 0s 468us/step - loss: 26747.6390 - val_loss: 27107.7552\n",
      "Epoch 485/500\n",
      "782/782 [==============================] - 0s 466us/step - loss: 26211.3690 - val_loss: 30108.3614\n",
      "Epoch 486/500\n",
      "782/782 [==============================] - 1s 752us/step - loss: 26051.5453 - val_loss: 27530.2157\n",
      "Epoch 487/500\n",
      "782/782 [==============================] - 0s 579us/step - loss: 25970.6140 - val_loss: 28268.6735\n",
      "Epoch 488/500\n",
      "782/782 [==============================] - 1s 674us/step - loss: 25823.2880 - val_loss: 27459.4957\n",
      "Epoch 489/500\n",
      "782/782 [==============================] - 0s 622us/step - loss: 25350.0648 - val_loss: 27761.8924\n",
      "Epoch 490/500\n",
      "782/782 [==============================] - 0s 529us/step - loss: 25274.7571 - val_loss: 26823.3811\n",
      "Epoch 491/500\n",
      "782/782 [==============================] - 1s 827us/step - loss: 26016.5375 - val_loss: 27506.5505\n",
      "Epoch 492/500\n",
      "782/782 [==============================] - 0s 505us/step - loss: 25460.8829 - val_loss: 26931.1668\n",
      "Epoch 493/500\n",
      "782/782 [==============================] - 0s 487us/step - loss: 25798.5488 - val_loss: 36070.7185\n",
      "Epoch 494/500\n",
      "782/782 [==============================] - 1s 740us/step - loss: 26614.3019 - val_loss: 27521.0265\n",
      "Epoch 495/500\n",
      "782/782 [==============================] - 0s 481us/step - loss: 25499.2139 - val_loss: 28927.8618\n",
      "Epoch 496/500\n",
      "782/782 [==============================] - 0s 461us/step - loss: 25613.8592 - val_loss: 28290.5048\n",
      "Epoch 497/500\n",
      "782/782 [==============================] - 1s 781us/step - loss: 25495.6152 - val_loss: 26990.5784\n",
      "Epoch 498/500\n",
      "782/782 [==============================] - 0s 444us/step - loss: 25316.8480 - val_loss: 26761.8668\n",
      "Epoch 499/500\n",
      "782/782 [==============================] - 0s 462us/step - loss: 25887.8945 - val_loss: 27251.1602\n",
      "Epoch 500/500\n",
      "782/782 [==============================] - 1s 800us/step - loss: 25445.0193 - val_loss: 29442.9271\n"
     ]
    }
   ],
   "source": [
    "model=classifier.fit(training,training_op,validation_split=0.33,batch_size=10,nb_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "def root_mean_squared_error(testing_op,pred):\n",
    "    return k.sqrt(k.mean(k.square(pred-testing_op)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[144634.1 ],\n",
       "       [210633.67],\n",
       "       [205145.31],\n",
       "       ...,\n",
       "       [245146.95],\n",
       "       [146212.75],\n",
       "       [296103.3 ]], dtype=float32)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_pred=classifier.predict(testing_data)\n",
    "ann_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ann_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\HOUSE PRICING\\sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],final_pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\HOUSE PRICING\\sample_submission_mine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>144634.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>210633.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>205145.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>207399.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>188508.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>99888.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>111123.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>245146.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>146212.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>296103.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice\n",
       "Id             \n",
       "1461  144634.10\n",
       "1462  210633.67\n",
       "1463  205145.31\n",
       "1464  207399.19\n",
       "1465  188508.81\n",
       "...         ...\n",
       "2915   99888.17\n",
       "2916  111123.20\n",
       "2917  245146.95\n",
       "2918  146212.75\n",
       "2919  296103.30\n",
       "\n",
       "[1459 rows x 1 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new=pd.read_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\HOUSE PRICING\\sample_submission_mine.csv')\n",
    "new=new.set_index('Id')\n",
    "new.to_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\HOUSE PRICING\\sample_submission_mine2.csv')\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
